{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Make unimodal network based of actors based on the books\n",
    "they worked on.\n",
    "@path: paths of actor,key.csv'''\n",
    "def to_unimodal(*args):\n",
    "    #Concat printers,publishers, and sellers in a dataframe\n",
    "    l=[]\n",
    "    for arg in args:\n",
    "        df=pd.read_csv(arg,index_col=0,engine='python')\n",
    "        df.columns=['key','person']\n",
    "        l.append(df)\n",
    "    df= pd.concat(l)\n",
    "    # make edgelist\n",
    "    edges=df.merge(df,on='key')\n",
    "    edges=edges.drop('key',axis=1).rename(columns={\n",
    "        'person_x':'Source','person_y':'Target'\n",
    "    })\n",
    "    edges=edges.query('Source<Target')\n",
    "    \n",
    "    #Create weight--edges attributes \n",
    "    edges['weight']=1\n",
    "    edges=edges.groupby(['Source','Target']).sum().reset_index()\n",
    "    G = nx.from_pandas_dataframe(edges,'Source','Target','weight')\n",
    "    commun=community.best_partition(G)\n",
    "    nx.set_node_attributes(G,'community',commun)\n",
    "    nx.set_node_attributes(G, 'k-core', nx.core_number(G))\n",
    "    nx.set_node_attributes(G,'betweenness',\n",
    "                            nx.betweenness_centrality(G,k=1000, normalized=True, weight='weight'))\n",
    "    #export Edges into a graphml file\n",
    "    nx.write_graphml(G,'actors.graphml', encoding='utf-8')\n",
    "    #export a graph where nodes are the communities\n",
    "    G_commun=community.induced_graph(commun, G)\n",
    "    nx.write_graphml(G_commun, 'actors_Community.graphml', encoding='utf-8')\n",
    "    #export nodes to a csv\n",
    "    name,attr=zip(*G.nodes(data=True))\n",
    "    com=[k['community'] for k in attr]\n",
    "    core=[k['k-core'] for k in attr]\n",
    "    btn=[k['betweenness'] for k in attr]\n",
    "    nodes_df=pd.DataFrame({'community':com,\n",
    "                          'k-core':core,\n",
    "                          'betweenness':btn},index=name)\n",
    "    nodes_df.to_csv('actors.csv',encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppl_book(*args):\n",
    "    l=[]\n",
    "    for arg in args:\n",
    "        df=pd.read_csv(arg,index_col=0,engine='python')\n",
    "        df.columns=['key','person']\n",
    "        l.append(df)\n",
    "    df= pd.concat(l)\n",
    "    df['weight']=1\n",
    "    #Make edgelist\n",
    "    edges=df.groupby(['key','person']).sum().reset_index()\n",
    "    ppl_dict=pd.Series('People',index=edges['person'].unique()).to_dict()\n",
    "    book_dict=pd.Series('Book',index=edges['key'].unique()).to_dict()\n",
    "    ppl_dict.update(book_dict)\n",
    "    edges.rename(columns={'person':'Source'\n",
    "                          ,'key':'Target'},inplace=True)\n",
    "     # make the people-book network\n",
    "    G = nx.from_pandas_dataframe(edges,'Source','Target','weight')\n",
    "    nx.set_node_attributes(G, 'Type', ppl_dict)\n",
    "    nx.set_node_attributes(G, \"k-core\", nx.core_number(G))\n",
    "    commun=community.best_partition(G)\n",
    "    nx.set_node_attributes(G,\"community\",commun)\n",
    "    nx.write_graphml(G, \"ppl_book.graphml\", encoding=\"utf-8\")\n",
    "    #export a graph where nodes are the communities\n",
    "    G_commun=community.induced_graph(commun, G)\n",
    "    nx.write_graphml(G_commun, 'ppl_book_Community.graphml', encoding='utf-8')\n",
    "    #export nodes to a csv\n",
    "    name,attr=zip(*G.nodes(data=True))\n",
    "    com=[k['community'] for k in attr]\n",
    "    core=[k['k-core'] for k in attr]\n",
    "    #btn=[k['betweenness'] for k in attr]\n",
    "    nodes_df=pd.DataFrame({'community':com,\n",
    "                          'k-core':core},index=name)\n",
    "    nodes_df.to_csv('ppl_book.csv',encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@Path=csv with standard names as columns, and their\n",
    "variations as rows,\n",
    "@nonstd=a series of unstandardized people names\n",
    "return a series of standardized people names'''\n",
    "def regNm(path,nonstd=None):\n",
    "    df=pd.read_csv(path)\n",
    "    std_dict=pd.melt(df).dropna().set_index('value').to_dict()['variable']\n",
    "    #Standardize names in a given series\n",
    "    #a filter than modified varied names who exist in the dictionary\n",
    "    def standardize_names(person):\n",
    "        if person in std_dict:\n",
    "            return std_dict[person]\n",
    "        else:\n",
    "            return person\n",
    "    res=nonstd.map(standardize_names)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
